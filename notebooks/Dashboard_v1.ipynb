{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyodbc\n",
    "import subprocess\n",
    "import io\n",
    "import os\n",
    "\n",
    "import matplotlib as plt\n",
    "\n",
    "# Ignore all warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to your Access database\n",
    "db_path = r'C:\\Users\\mehak.rafiq.ASKARIBANK\\Documents\\Projects\\model_data\\Daily_Dashboard_NTB\\Data\\Account_Holders_Weekly_be.accdb'\n",
    "\n",
    "# Connection string\n",
    "conn_str = (\n",
    "    r\"DRIVER={Microsoft Access Driver (*.mdb, *.accdb)};\"\n",
    "    f\"DBQ={db_path};\"\n",
    ")\n",
    "\n",
    "try:\n",
    "    # Establish a connection\n",
    "    with pyodbc.connect(conn_str) as conn:\n",
    "        cursor = conn.cursor()\n",
    "\n",
    "        # Retrieve table names\n",
    "        cursor.tables()\n",
    "        table_names = [row.table_name for row in cursor if row.table_type == 'TABLE']\n",
    "        print(\"Tables in the database:\", table_names)\n",
    "\n",
    "        # Load each table into a Pandas DataFrame\n",
    "        tables_data = {}\n",
    "        for table_name in table_names:\n",
    "            query = f\"SELECT * FROM [{table_name}]\"\n",
    "            tables_data[table_name] = pd.read_sql(query, conn)\n",
    "            print(f\"Loaded table: {table_name}\")\n",
    "\n",
    "except pyodbc.Error as e:\n",
    "    print(\"Database connection error:\", e)\n",
    "except Exception as e:\n",
    "    print(\"Error:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new folder called './Data/CSVs' if it doesn't exist\n",
    "# Creat in a one directory up\n",
    "os.makedirs('./Data/CSVs', exist_ok=True)\n",
    "\n",
    "\n",
    "# Save each table as a separate CSV file in the './Data/CSVs' folder\n",
    "for table_name, df in tables_data.items():\n",
    "    csv_path = os.path.join('./Data/CSVs', f\"{table_name}.csv\")\n",
    "    df.to_csv(csv_path, index=False)\n",
    "    print(f\"Saved {table_name} to {csv_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to ntb_reg_tbl\n",
    "ntb_reg_tbl_csv_path = os.path.join('./Data/CSVs', 'NTB_Reg_Summary.csv')\n",
    "\n",
    "# Load the CSV file into a DataFrame\n",
    "ntb_reg_tbl_df = pd.read_csv(ntb_reg_tbl_csv_path)\n",
    "\n",
    "# Print Shape of the DataFrame\n",
    "print(f\"Shape of the DataFrame: {ntb_reg_tbl_df.shape}\")\n",
    "\n",
    "# Display the DataFrame\n",
    "ntb_reg_tbl_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find Unique values in Login_Bracket\n",
    "print(ntb_reg_tbl_df['Login_Bracket'].unique())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert date columns to datetime\n",
    "ntb_reg_tbl_df['Registration_Date'] = pd.to_datetime(ntb_reg_tbl_df['Registration_Date'])\n",
    "ntb_reg_tbl_df['Open_Date_'] = pd.to_datetime(ntb_reg_tbl_df['Open_Date_'])\n",
    "\n",
    "# Create mask for records where Registration_Date is older than Open_Date_\n",
    "older_reg_mask = ntb_reg_tbl_df['Registration_Date'] < ntb_reg_tbl_df['Open_Date_']\n",
    "\n",
    "# Update Registration_Remarks where mask is True\n",
    "ntb_reg_tbl_df.loc[older_reg_mask, 'Registration_Remarks'] = 'Already Registered'\n",
    "\n",
    "# Count number of updates\n",
    "num_updates = older_reg_mask.sum()\n",
    "\n",
    "print(f\"Number of records updated to 'Already Registered': {num_updates}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Len of CUST_AC_NO\n",
    "print(len(ntb_reg_tbl_df['CUST_AC_NO'].unique()))\n",
    "\n",
    "# Percentage of records updated to 'Already Registered'\n",
    "print(f\"Percentage of records updated to 'Already Registered': {num_updates / len(ntb_reg_tbl_df) * 100}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Last_Login_Da to datetime\n",
    "ntb_reg_tbl_df['Last_Login_Date'] = pd.to_datetime(ntb_reg_tbl_df['Last_Login_Date'])\n",
    "\n",
    "# Get current date\n",
    "current_date = pd.Timestamp.now()\n",
    "\n",
    "# Create conditions for different time brackets\n",
    "last_30_days = current_date - pd.Timedelta(days=30)\n",
    "last_90_days = current_date - pd.Timedelta(days=90) \n",
    "last_year = current_date - pd.Timedelta(days=365)\n",
    "\n",
    "# Create Login_Bracket column\n",
    "def get_login_bracket(login_date, registration_date):\n",
    "    if pd.isna(login_date):\n",
    "        if pd.notna(registration_date):\n",
    "            return 'More than a Year'\n",
    "        return 'Not Registered'\n",
    "    elif login_date >= last_30_days:\n",
    "        return 'Last 30 Days'\n",
    "    elif login_date >= last_90_days:\n",
    "        return 'Last 90 Days'\n",
    "    elif login_date >= last_year:\n",
    "        return 'Previous Year'\n",
    "    else:\n",
    "        return 'More than a Year'\n",
    "\n",
    "ntb_reg_tbl_df['Login_Bracket'] = ntb_reg_tbl_df.apply(\n",
    "    lambda x: get_login_bracket(x['Last_Login_Date'], x['Registration_Date']), \n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Print value counts to see distribution\n",
    "print(\"\\nLogin Bracket Distribution:\")\n",
    "value_counts = ntb_reg_tbl_df['Login_Bracket'].value_counts(dropna=False)\n",
    "print(value_counts)\n",
    "print(f\"\\nTotal: {value_counts.sum()}\")\n",
    "# Create a bar chart comparing months between 2024 and 2025\n",
    "# First extract year and month from Open_Date_\n",
    "ntb_reg_tbl_df['Year'] = ntb_reg_tbl_df['Open_Date_'].dt.year\n",
    "ntb_reg_tbl_df['Month'] = ntb_reg_tbl_df['Open_Date_'].dt.month\n",
    "\n",
    "# Get monthly counts for each year\n",
    "monthly_counts = ntb_reg_tbl_df.groupby(['Year', 'Month']).size().reset_index(name='Count')\n",
    "\n",
    "# Filter for just 2024 and 2025\n",
    "monthly_counts = monthly_counts[monthly_counts['Year'].isin([2024, 2025])]\n",
    "\n",
    "# Create the bar plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "bar_width = 0.35\n",
    "\n",
    "# Plot bars for each year\n",
    "plt.bar(monthly_counts[monthly_counts['Year']==2024]['Month'] - bar_width/2, \n",
    "        monthly_counts[monthly_counts['Year']==2024]['Count'],\n",
    "        bar_width, label='2024')\n",
    "plt.bar(monthly_counts[monthly_counts['Year']==2025]['Month'] + bar_width/2,\n",
    "        monthly_counts[monthly_counts['Year']==2025]['Count'], \n",
    "        bar_width, label='2025')\n",
    "\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Number of Accounts')\n",
    "plt.title('Monthly Account Distribution: 2024 vs 2025')\n",
    "plt.legend()\n",
    "plt.xticks(range(1,13))\n",
    "plt.grid(True, alpha=0.3)\n",
    "# Save plot with datetime stamp\n",
    "current_time = pd.Timestamp.now().strftime('%Y%m%d_%H%M%S')\n",
    "save_path = os.path.join('./Figures', f'monthly_accounts_{current_time}.png')\n",
    "\n",
    "# Create Figures directory if it doesn't exist\n",
    "os.makedirs('./Figures', exist_ok=True)\n",
    "\n",
    "plt.savefig(save_path, bbox_inches='tight', dpi=300)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Print summary statistics\n",
    "print(\"\\nMonthly Account Summary:\")\n",
    "print(monthly_counts.sort_values(['Year', 'Month']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert date columns to datetime with consistent format handling\n",
    "ntb_reg_tbl_df['Registration_Date'] = pd.to_datetime(ntb_reg_tbl_df['Registration_Date'], errors='coerce')\n",
    "ntb_reg_tbl_df['Open_Date_'] = pd.to_datetime(ntb_reg_tbl_df['Open_Date_'], errors='coerce')\n",
    "\n",
    "# Create mask for valid onboarding calculation (both dates exist and registration after opening)\n",
    "valid_onboarding_mask = (~ntb_reg_tbl_df['Registration_Date'].isna()) & (~ntb_reg_tbl_df['Open_Date_'].isna()) & (ntb_reg_tbl_df['Registration_Date'] >= ntb_reg_tbl_df['Open_Date_'])\n",
    "\n",
    "# Calculate days to onboard\n",
    "ntb_reg_tbl_df.loc[valid_onboarding_mask, 'Days_to_Onboard'] = (\n",
    "    ntb_reg_tbl_df.loc[valid_onboarding_mask, 'Registration_Date'] - \n",
    "    ntb_reg_tbl_df.loc[valid_onboarding_mask, 'Open_Date_']\n",
    ").dt.days\n",
    "\n",
    "# Get overall average\n",
    "avg_days_to_onboard = ntb_reg_tbl_df['Days_to_Onboard'].mean()\n",
    "print(f\"Average days to onboard: {avg_days_to_onboard:.2f}\")\n",
    "\n",
    "# Get average by region\n",
    "region_onboarding = ntb_reg_tbl_df.groupby('REGION_DESC')['Days_to_Onboard'].mean().reset_index()\n",
    "print(\"\\nAverage onboarding time by region:\")\n",
    "print(region_onboarding.sort_values('Days_to_Onboard'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create bins for customers with login data\n",
    "login_mask = ~ntb_reg_tbl_df['Last_Login_Date'].isna()\n",
    "current_date = pd.Timestamp.now()\n",
    "\n",
    "# Calculate days since last login\n",
    "ntb_reg_tbl_df.loc[login_mask, 'Days_Since_Last_Login'] = (\n",
    "    current_date - ntb_reg_tbl_df.loc[login_mask, 'Last_Login_Date']\n",
    ").dt.days\n",
    "\n",
    "# Create frequency categories \n",
    "def get_login_frequency(days):\n",
    "    if pd.isna(days):\n",
    "        return 'No Login'\n",
    "    elif days <= 7:\n",
    "        return 'Weekly'\n",
    "    elif days <= 30:\n",
    "        return 'Monthly'\n",
    "    elif days <= 90:\n",
    "        return 'Quarterly'\n",
    "    else:\n",
    "        return 'Inactive'\n",
    "\n",
    "ntb_reg_tbl_df['Login_Frequency'] = ntb_reg_tbl_df['Days_Since_Last_Login'].apply(get_login_frequency)\n",
    "\n",
    "# Update 'No Login' to 'Not Registered' when Registration_Remarks is 'Not Registered'\n",
    "not_registered_mask = (ntb_reg_tbl_df['Login_Frequency'] == 'No Login') & (ntb_reg_tbl_df['Registration_Remarks'] == 'Not Registered')\n",
    "ntb_reg_tbl_df.loc[not_registered_mask, 'Login_Frequency'] = 'Not Registered'\n",
    "\n",
    "# Verify the changes\n",
    "print(\"\\nUpdated Login Frequency Distribution:\")\n",
    "updated_freq_dist = ntb_reg_tbl_df['Login_Frequency'].value_counts().reset_index()\n",
    "updated_freq_dist.columns = ['Frequency', 'Count']\n",
    "print(updated_freq_dist)\n",
    "\n",
    "# Calculate frequency distribution\n",
    "login_frequency_dist = ntb_reg_tbl_df['Login_Frequency'].value_counts().reset_index()\n",
    "login_frequency_dist.columns = ['Frequency', 'Count']\n",
    "\n",
    "print(\"\\nLogin Frequency Distribution:\")\n",
    "print(login_frequency_dist)\n",
    "\n",
    "# Calculate by region\n",
    "region_frequency = pd.crosstab(\n",
    "    ntb_reg_tbl_df['REGION_DESC'], \n",
    "    ntb_reg_tbl_df['Login_Frequency'],\n",
    "    normalize='index'\n",
    ") * 100\n",
    "\n",
    "print(\"\\nLogin Frequency by Region (%):\")\n",
    "print(region_frequency)\n",
    "\n",
    "\n",
    "# Define a clean order for the categories\n",
    "category_order = ['Weekly', 'Monthly', 'Quarterly', 'Inactive', 'No Login', 'Not Registered']\n",
    "# Filter to only include categories in our data\n",
    "valid_categories = [cat for cat in category_order if cat in login_frequency_dist['Frequency'].values]\n",
    "# Filter and sort the dataframe\n",
    "sorted_dist = login_frequency_dist[login_frequency_dist['Frequency'].isin(valid_categories)]\n",
    "sorted_dist = sorted_dist.set_index('Frequency').reindex(valid_categories).reset_index()\n",
    "\n",
    "\n",
    "# Calculate login frequency by RGM\n",
    "rgm_frequency = pd.crosstab(\n",
    "    ntb_reg_tbl_df['RGM'],\n",
    "    ntb_reg_tbl_df['Login_Frequency'],\n",
    "    normalize='index'\n",
    ") * 100\n",
    "\n",
    "# Calculate active user rate (Weekly + Monthly) by RGM\n",
    "if 'Weekly' in rgm_frequency.columns and 'Monthly' in rgm_frequency.columns:\n",
    "    active_cols = ['Weekly', 'Monthly']\n",
    "    rgm_active_rate = rgm_frequency[active_cols].sum(axis=1).sort_values(ascending=False)\n",
    "    \n",
    "    print(\"\\nTop 10 RGMs by Active User Rate (Weekly + Monthly):\")\n",
    "    print(rgm_active_rate.head(10).round(1))\n",
    "    \n",
    "    # Save RGM active user rates\n",
    "    rgm_active_rate = rgm_active_rate.reset_index()\n",
    "    rgm_active_rate.columns = ['RGM', 'Active_User_Rate']\n",
    "    rgm_active_rate.to_excel('./Notebook_reports/rgm_active_user_rates.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure dates are in datetime format\n",
    "ntb_reg_tbl_df['Registration_Date'] = pd.to_datetime(ntb_reg_tbl_df['Registration_Date'], errors='coerce')\n",
    "ntb_reg_tbl_df['Open_Date_'] = pd.to_datetime(ntb_reg_tbl_df['Open_Date_'], errors='coerce')\n",
    "\n",
    "# Initialize Days_to_Onboard column as NaN\n",
    "ntb_reg_tbl_df['Days_to_Onboard'] = np.nan\n",
    "\n",
    "# Create a mask for eligible records:\n",
    "# 1. Not 'Already Registered'\n",
    "# 2. Has both dates\n",
    "# 3. Registration date is after or equal to open date\n",
    "eligible_mask = (\n",
    "    (ntb_reg_tbl_df['Registration_Remarks'] != 'Already Registered') & \n",
    "    (~ntb_reg_tbl_df['Registration_Date'].isna()) & \n",
    "    (~ntb_reg_tbl_df['Open_Date_'].isna()) & \n",
    "    (ntb_reg_tbl_df['Registration_Date'] >= ntb_reg_tbl_df['Open_Date_'])\n",
    ")\n",
    "\n",
    "# Calculate days to onboard only for eligible records\n",
    "ntb_reg_tbl_df.loc[eligible_mask, 'Days_to_Onboard'] = (\n",
    "    ntb_reg_tbl_df.loc[eligible_mask, 'Registration_Date'] - \n",
    "    ntb_reg_tbl_df.loc[eligible_mask, 'Open_Date_']\n",
    ").dt.days\n",
    "\n",
    "# Create days_to_onboard categories\n",
    "def get_onboarding_bracket(days):\n",
    "    if pd.isna(days):\n",
    "        return 'Not Registered'\n",
    "    elif days <= 5:\n",
    "        return '5 days or less'\n",
    "    elif days <= 10:\n",
    "        return '6-10 days'\n",
    "    elif days <= 30:\n",
    "        return '11-30 days'\n",
    "    elif days <= 180:\n",
    "        return '1-6 months'\n",
    "    else:\n",
    "        return 'More than 6 months'\n",
    "\n",
    "# Apply the binning function to eligible records\n",
    "ntb_reg_tbl_df['Onboarding_Time_Bracket'] = 'Not Registered'  # Default value\n",
    "ntb_reg_tbl_df.loc[eligible_mask, 'Onboarding_Time_Bracket'] = ntb_reg_tbl_df.loc[eligible_mask, 'Days_to_Onboard'].apply(get_onboarding_bracket)\n",
    "\n",
    "# Update Onboarding_Time_Bracket to \"Already Registered\" for customers with Registration_Remarks = \"Already Registered\"\n",
    "already_registered_mask = ntb_reg_tbl_df['Registration_Remarks'] == 'Already Registered'\n",
    "ntb_reg_tbl_df.loc[already_registered_mask, 'Onboarding_Time_Bracket'] = 'Already Registered'\n",
    "\n",
    "# Summary statistics\n",
    "valid_days = ntb_reg_tbl_df.loc[eligible_mask, 'Days_to_Onboard']\n",
    "print(f\"\\nDays to Onboard - Summary Statistics:\")\n",
    "print(f\"Count: {valid_days.count()}\")\n",
    "print(f\"Mean: {valid_days.mean():.2f} days\")\n",
    "print(f\"Median: {valid_days.median():.0f} days\")\n",
    "print(f\"Min: {valid_days.min():.0f} days\")\n",
    "print(f\"Max: {valid_days.max():.0f} days\")\n",
    "\n",
    "# Distribution of onboarding time brackets\n",
    "print(\"\\nOnboarding Time Bracket Distribution:\")\n",
    "onboard_dist = ntb_reg_tbl_df['Onboarding_Time_Bracket'].value_counts().sort_index()\n",
    "print(onboard_dist)\n",
    "\n",
    "# Exclude 'Not Registered' and 'Already Registered' for percentage calculation of normal onboarding times\n",
    "normal_onboarding_mask = eligible_mask\n",
    "onboard_dist_pct = ntb_reg_tbl_df.loc[normal_onboarding_mask, 'Onboarding_Time_Bracket'].value_counts(normalize=True) * 100\n",
    "print(\"\\nOnboarding Time Bracket Distribution (% of normally registered customers):\")\n",
    "print(onboard_dist_pct.sort_index().round(2))\n",
    "\n",
    "# Create a filtered dataframe for non-'Already Registered' users for regional and RGM analysis\n",
    "# This is needed to get accurate regional and RGM insights about normal onboarding patterns\n",
    "real_ntb_reg_tbl_df = ntb_reg_tbl_df[ntb_reg_tbl_df['Registration_Remarks'] != 'Already Registered']\n",
    "\n",
    "# Regional analysis of onboarding time brackets\n",
    "region_onboard = pd.crosstab(\n",
    "    real_ntb_reg_tbl_df['REGION_DESC'],\n",
    "    real_ntb_reg_tbl_df['Onboarding_Time_Bracket'],\n",
    "    normalize='index'\n",
    ") * 100\n",
    "\n",
    "print(\"\\nDays to Onboard by Region (%):\")\n",
    "if 'Not Registered' in region_onboard.columns:\n",
    "    # Move 'Not Registered' to the end for better readability\n",
    "    cols = [col for col in region_onboard.columns if col != 'Not Registered'] + ['Not Registered']\n",
    "    region_onboard = region_onboard[cols]\n",
    "\n",
    "print(region_onboard.round(1))\n",
    "\n",
    "# Save the region analysis\n",
    "region_onboard.to_excel('./Notebook_reports/region_onboarding_time.xlsx')\n",
    "\n",
    "# Additional analysis: RGM-level onboarding performance\n",
    "rgm_onboard = pd.crosstab(\n",
    "    real_ntb_reg_tbl_df['RGM'],\n",
    "    real_ntb_reg_tbl_df['Onboarding_Time_Bracket'],\n",
    "    normalize='index'\n",
    ") * 100\n",
    "\n",
    "# Calculate key metrics for RGMs\n",
    "rgm_metrics = real_ntb_reg_tbl_df.groupby('RGM').agg(\n",
    "    Total_Accounts=('CUSTOMER_NO', 'count'),\n",
    "    Registered_Count=('Registration_Date', lambda x: x.notna().sum()),\n",
    "    Average_Days_to_Onboard=('Days_to_Onboard', 'mean')\n",
    ").reset_index()\n",
    "\n",
    "# Calculate registration rate\n",
    "rgm_metrics['Registration_Rate'] = (rgm_metrics['Registered_Count'] / rgm_metrics['Total_Accounts'] * 100).round(1)\n",
    "\n",
    "# Calculate % of quick onboarders (<=10 days)\n",
    "quick_onboarders = pd.crosstab(\n",
    "    real_ntb_reg_tbl_df['RGM'],\n",
    "    real_ntb_reg_tbl_df['Onboarding_Time_Bracket'].isin(['5 days or less', '6-10 days']),\n",
    "    normalize='index'\n",
    ") * 100\n",
    "\n",
    "if True in quick_onboarders.columns:\n",
    "    rgm_metrics['Quick_Onboarding_Rate'] = quick_onboarders[True].round(1)\n",
    "else:\n",
    "    rgm_metrics['Quick_Onboarding_Rate'] = 0\n",
    "\n",
    "# Sort by Quick Onboarding Rate\n",
    "rgm_metrics = rgm_metrics.sort_values('Quick_Onboarding_Rate', ascending=False)\n",
    "\n",
    "print(\"\\nRGM Performance in Onboarding:\")\n",
    "print(rgm_metrics.head(10))  # Top 10 RGMs\n",
    "\n",
    "# Save RGM analysis\n",
    "rgm_metrics.to_excel('./Notebook_reports/rgm_onboarding_performance.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract month from registration date\n",
    "ntb_reg_tbl_df['Registration_Month'] = ntb_reg_tbl_df['Registration_Date'].dt.to_period('M')\n",
    "\n",
    "# Calculate monthly onboarding times\n",
    "monthly_onboarding = ntb_reg_tbl_df.groupby('Registration_Month')['Days_to_Onboard'].agg(['mean', 'median', 'count']).reset_index()\n",
    "monthly_onboarding = monthly_onboarding.sort_values('Registration_Month')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Branch performance metrics\n",
    "branch_metrics = ntb_reg_tbl_df.groupby('BRANCH_NAME').agg(\n",
    "    Total_Accounts=('CUSTOMER_NO', 'count'),\n",
    "    Registered_Count=('Registration_Date', lambda x: x.notna().sum()),\n",
    "    Avg_Days_to_Onboard=('Days_to_Onboard', 'mean')\n",
    ").reset_index()\n",
    "\n",
    "# Calculate registration rate and add REGION_DESC\n",
    "branch_metrics['Registration_Rate'] = (branch_metrics['Registered_Count'] / branch_metrics['Total_Accounts'] * 100).round(1)\n",
    "\n",
    "# Add region info to branch metrics (based on a single branch's region)\n",
    "branch_region = ntb_reg_tbl_df.groupby('BRANCH_NAME')['REGION_DESC'].first().reset_index()\n",
    "branch_metrics = pd.merge(branch_metrics, branch_region, on='BRANCH_NAME')\n",
    "\n",
    "# Identify top and bottom performing branches\n",
    "top_branches = branch_metrics.sort_values('Registration_Rate', ascending=False).head(20)\n",
    "bottom_branches = branch_metrics.sort_values('Registration_Rate').head(20)\n",
    "\n",
    "# Save branch metrics\n",
    "branch_metrics.to_excel('./Notebook_reports/branch_onboarding_performance.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define funnel stages\n",
    "funnel_data = {\n",
    "    'Stage': ['Account Opening', 'Mobile Registration', 'Active in Last 30 Days', 'Weekly Active Users'],\n",
    "    'Count': [\n",
    "        len(ntb_reg_tbl_df),  # All accounts\n",
    "        ntb_reg_tbl_df['Registration_Remarks'].isin(['Registered', 'Already Registered']).sum(),  # All registered\n",
    "        (ntb_reg_tbl_df['Login_Bracket'] == 'Last 30 Days').sum(),  # Active in last 30 days\n",
    "        (ntb_reg_tbl_df['Login_Frequency'] == 'Weekly').sum()  # Log in weekly\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Create dataframe\n",
    "funnel_df = pd.DataFrame(funnel_data)\n",
    "\n",
    "# Calculate percentage of total accounts\n",
    "funnel_df['Percentage'] = (funnel_df['Count'] / funnel_df['Count'][0] * 100).round(1)\n",
    "\n",
    "# Calculate stage-to-stage conversion rates\n",
    "funnel_df['Conversion_Rate'] = 100.0  # Initialize with a default value for all rows\n",
    "\n",
    "# Update conversion rates for rows after the first one\n",
    "for i in range(1, len(funnel_df)):\n",
    "    # Conversion from previous stage to current stage\n",
    "    funnel_df.loc[i, 'Conversion_Rate'] = (funnel_df['Count'][i] / funnel_df['Count'][i-1] * 100).round(1)\n",
    "\n",
    "# Add stage drop-off\n",
    "funnel_df['Drop_Off'] = 100 - funnel_df['Conversion_Rate']\n",
    "\n",
    "print(\"Customer Journey Funnel:\")\n",
    "print(funnel_df)\n",
    "\n",
    "\n",
    "# Export to Excel for dashboard\n",
    "funnel_df.to_excel('./Notebook_reports/customer_journey_funnel.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create funnel by region\n",
    "regions = ntb_reg_tbl_df['REGION_DESC'].unique()\n",
    "region_funnels = []\n",
    "\n",
    "for region in regions:\n",
    "    region_data = ntb_reg_tbl_df[ntb_reg_tbl_df['REGION_DESC'] == region]\n",
    "    \n",
    "    funnel = {\n",
    "        'Region': region,\n",
    "        'Total_Accounts': len(region_data),\n",
    "        'Registered': region_data['Registration_Remarks'].isin(['Registered', 'Already Registered']).sum(),\n",
    "        'Active_30_Days': (region_data['Login_Bracket'] == 'Last 30 Days').sum(),\n",
    "        'Weekly_Users': (region_data['Login_Frequency'] == 'Weekly').sum()\n",
    "    }\n",
    "    \n",
    "    region_funnels.append(funnel)\n",
    "\n",
    "region_funnel_df = pd.DataFrame(region_funnels)\n",
    "\n",
    "# Calculate conversion rates\n",
    "region_funnel_df['Registration_Rate'] = (region_funnel_df['Registered'] / region_funnel_df['Total_Accounts'] * 100).round(1)\n",
    "region_funnel_df['Activation_Rate'] = (region_funnel_df['Active_30_Days'] / region_funnel_df['Registered'] * 100).round(1)\n",
    "region_funnel_df['Weekly_Usage_Rate'] = (region_funnel_df['Weekly_Users'] / region_funnel_df['Active_30_Days'] * 100).round(1)\n",
    "\n",
    "# Sort by Registration Rate\n",
    "region_funnel_df = region_funnel_df.sort_values('Registration_Rate', ascending=False)\n",
    "\n",
    "# Print the regional funnel analysis\n",
    "print(\"\\nRegional Funnel Analysis:\")\n",
    "print(region_funnel_df)\n",
    "\n",
    "# Save to Excel\n",
    "region_funnel_df.to_excel('./Notebook_reports/regional_funnel_analysis.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by account opening month\n",
    "ntb_reg_tbl_df['Open_Month'] = pd.to_datetime(ntb_reg_tbl_df['Open_Date_']).dt.to_period('M')\n",
    "\n",
    "# Create monthly cohorts and track their progression through the funnel\n",
    "monthly_cohorts = []\n",
    "\n",
    "for month in sorted(ntb_reg_tbl_df['Open_Month'].unique()):\n",
    "    cohort = ntb_reg_tbl_df[ntb_reg_tbl_df['Open_Month'] == month]\n",
    "    \n",
    "    # Calculate funnel metrics for this cohort\n",
    "    metrics = {\n",
    "        'Cohort_Month': str(month),  # Convert to string for display\n",
    "        'Total_Accounts': len(cohort),\n",
    "        'Registered_30d': cohort[\n",
    "            (cohort['Registration_Date'].notna()) & \n",
    "            ((cohort['Registration_Date'] - cohort['Open_Date_']).dt.days <= 30)\n",
    "        ].shape[0],\n",
    "        'Registered_90d': cohort[\n",
    "            (cohort['Registration_Date'].notna()) & \n",
    "            ((cohort['Registration_Date'] - cohort['Open_Date_']).dt.days <= 90)\n",
    "        ].shape[0]\n",
    "    }\n",
    "    \n",
    "    monthly_cohorts.append(metrics)\n",
    "\n",
    "monthly_funnel_df = pd.DataFrame(monthly_cohorts)\n",
    "monthly_funnel_df['30d_Registration_Rate'] = (monthly_funnel_df['Registered_30d'] / monthly_funnel_df['Total_Accounts'] * 100).round(1)\n",
    "monthly_funnel_df['90d_Registration_Rate'] = (monthly_funnel_df['Registered_90d'] / monthly_funnel_df['Total_Accounts'] * 100).round(1)\n",
    "\n",
    "# Print the monthly cohort analysis\n",
    "print(\"\\nMonthly Cohort Analysis:\")\n",
    "print(monthly_funnel_df)\n",
    "\n",
    "# Save to Excel\n",
    "monthly_funnel_df.to_excel('./Notebook_reports/monthly_cohort_analysis.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create summary metrics for dashboard\n",
    "summary_metrics = {\n",
    "    'Metric': [\n",
    "        'Total Accounts',\n",
    "        'Registered Accounts',\n",
    "        'Registration Rate',\n",
    "        'Active 30 Days',\n",
    "        'Active Rate',\n",
    "        'Avg Days to Onboard',\n",
    "        'Already Registered',\n",
    "        'Quick Onboarding (≤10 days)'\n",
    "    ],\n",
    "    'Value': [\n",
    "        len(ntb_reg_tbl_df),\n",
    "        ntb_reg_tbl_df['Registration_Remarks'].isin(['Registered', 'Already Registered']).sum(),\n",
    "        ntb_reg_tbl_df['Registration_Remarks'].isin(['Registered', 'Already Registered']).sum() / len(ntb_reg_tbl_df) * 100,\n",
    "        (ntb_reg_tbl_df['Login_Bracket'] == 'Last 30 Days').sum(),\n",
    "        (ntb_reg_tbl_df['Login_Bracket'] == 'Last 30 Days').sum() / ntb_reg_tbl_df['Registration_Remarks'].isin(['Registered', 'Already Registered']).sum() * 100,\n",
    "        ntb_reg_tbl_df['Days_to_Onboard'].mean(),\n",
    "        (ntb_reg_tbl_df['Registration_Remarks'] == 'Already Registered').sum(),\n",
    "        ntb_reg_tbl_df['Onboarding_Time_Bracket'].isin(['5 days or less', '6-10 days']).sum() / ntb_reg_tbl_df['Registration_Remarks'].isin(['Registered', 'Already Registered']).sum() * 100\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Convert to DataFrame for easy export\n",
    "summary_df = pd.DataFrame(summary_metrics)\n",
    "summary_df['Value'] = summary_df['Value'].round(2)\n",
    "print(\"\\nSummary Metrics:\")\n",
    "print(summary_df)\n",
    "\n",
    "# Export summary metrics to Excel\n",
    "summary_df.to_excel('./Notebook_reports/Mobile_Banking_Summary_Metrics.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save the updated main dataframe with onboarding metrics\n",
    "ntb_reg_tbl_df.to_excel('./Notebook_reports/NTB_Reg_Summary_with_Onboarding.xlsx', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DBD_analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
